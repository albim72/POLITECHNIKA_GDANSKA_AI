{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RLBUQhme9bAa"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# ---- 1. Dane treningowe ----\n",
        "texts = [\n",
        "    \"sztuczna inteligencja zmienia świat\",\n",
        "    \"sztuczna inteligencja tworzy nowe możliwości\",\n",
        "    \"model językowy przewiduje słowa\",\n",
        "    \"model językowy uczy się z danych\"\n",
        "]\n",
        "\n",
        "# ---- 2. Tokenizacja ----\n",
        "tok = Tokenizer()\n",
        "tok.fit_on_texts(texts)\n",
        "sequences = []\n",
        "\n",
        "for line in texts:\n",
        "    tokens = tok.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(tokens)):\n",
        "        sequences.append(tokens[:i+1])\n",
        "\n",
        "# np. [sztuczna, inteligencja] -> target: inteligencja\n",
        "\n",
        "max_len = max(len(s) for s in sequences)\n",
        "sequences = pad_sequences(sequences, maxlen=max_len, padding=\"pre\")\n",
        "\n",
        "sequences = np.array(sequences)\n",
        "X = sequences[:, :-1]\n",
        "y = sequences[:, -1]\n",
        "\n",
        "vocab_size = len(tok.word_index) + 1\n",
        "\n",
        "# ---- 3. Model językowy ----\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Embedding(vocab_size, 16, input_length=max_len-1),\n",
        "    tf.keras.layers.LSTM(32),\n",
        "    tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\n",
        "])\n",
        "\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"adam\")\n",
        "model.summary()\n",
        "\n",
        "# ---- 4. Trening ----\n",
        "model.fit(X, y, epochs=30, verbose=0)\n",
        "\n",
        "# ---- 5. Funkcja generowania słów ----\n",
        "def predict_next(text, n=3):\n",
        "    for _ in range(n):\n",
        "        seq = tok.texts_to_sequences([text])[0]\n",
        "        seq = pad_sequences([seq], maxlen=max_len-1, padding=\"pre\")\n",
        "        pred = model.predict(seq, verbose=0).argmax()\n",
        "        word = tok.index_word.get(pred, \"\")\n",
        "        text += \" \" + word\n",
        "    return text\n",
        "\n",
        "print(predict_next(\"model językowy\"))\n",
        "print(predict_next(\"sztuczna inteligencja\"))\n"
      ]
    }
  ]
}